# ğŸƒ ALLMond

**Natural Language Processing pipeline as simple and delicious as an almond.**

Un framework completo e professionale per progetti di NLP in italiano (e altre lingue).

---

## ğŸš€ Caratteristiche

- âœ… **Pipeline completa NLP**: dalla raccolta dati al deployment
- âœ… **Preprocessing avanzato**: pulizia testo, tokenizzazione, lemmatization
- âœ… **Feature extraction**: BoW, TF-IDF, Word2Vec, Topic Modeling
- âœ… **Modelli ML**: Naive Bayes, Logistic Regression, SVM, Random Forest
- âœ… **Web Scraping**: strumenti per raccolta dati da web
- âœ… **Jupyter Notebook**: tutorial interattivo completo
- âœ… **Testing**: suite di test con pytest
- âœ… **Logging**: sistema di logging professionale
- âœ… **CLI Scripts**: script pronti per training e predizione
- âœ… **Configurabile**: gestione configurazione tramite file .env

---

## ğŸ“¦ Installazione

### Prerequisiti

- Python 3.9+
- pip
- virtualenv (consigliato)

### Setup Rapido

```bash
# Clona il repository
git clone https://github.com/your-username/ALLMond.git
cd ALLMond

# Crea ambiente virtuale
python -m venv .venv

# Attiva ambiente virtuale
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate

# Installa dipendenze
pip install -r requirements.txt

# Download risorse NLTK
python scripts/download_nltk_data.py

# (Opzionale) Installa spaCy per italiano
python -m spacy download it_core_news_sm
```

### Setup con Make (consigliato)

```bash
make setup
```

---

## ğŸ¯ Quick Start

### 1. Jupyter Notebook (per principianti)

```bash
make run-notebook
# oppure
jupyter notebook
```

Apri `notebooks/nlp_pipeline.ipynb` e segui le istruzioni passo-passo.

### 2. Training da CLI

```bash
python scripts/train_pipeline.py \
    --input-file data/raw/your_data.csv \
    --text-column "text" \
    --label-column "category" \
    --model logistic_regression \
    --language italian

# Oppure con Make
make train ARGS="--input-file data/raw/your_data.csv --text-column text"
```

### 3. Uso Programmatico

```python
from src.data_loader import DataLoader
from src.text_preprocessing import TextPreprocessor
from src.model_trainer import ModelTrainer

# Carica dati
loader = DataLoader()
df = loader.load_csv("data/raw/your_data.csv")

# Preprocessing
preprocessor = TextPreprocessor(language="italian")
df_clean = preprocessor.preprocess_dataframe(df, text_column="text")

# Training
trainer = ModelTrainer(model_type="logistic_regression")
trainer.train(X_train, y_train)

# Valutazione
metrics = trainer.evaluate(X_test, y_test)
print(metrics)
```

---

## ğŸ“ Struttura Progetto

```
ALLMond/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Dati originali
â”‚   â”œâ”€â”€ processed/        # Dati intermedi
â”‚   â””â”€â”€ cleaned/          # Dati puliti finali
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ nlp_pipeline.ipynb  # Tutorial completo
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py         # Configurazione
â”‚   â”œâ”€â”€ logger.py         # Sistema logging
â”‚   â”œâ”€â”€ data_loader.py    # Caricamento dati
â”‚   â”œâ”€â”€ text_preprocessing.py  # Preprocessing testo
â”‚   â”œâ”€â”€ feature_extraction.py  # Estrazione features
â”‚   â”œâ”€â”€ model_trainer.py  # Training modelli
â”‚   â”œâ”€â”€ scraper.py        # Web scraping
â”‚   â””â”€â”€ utils.py          # UtilitÃ  varie
â”œâ”€â”€ tests/                # Test suite
â”œâ”€â”€ scripts/              # Script CLI
â”œâ”€â”€ models/               # Modelli salvati
â”œâ”€â”€ logs/                 # File di log
â”œâ”€â”€ docs/                 # Documentazione
â”œâ”€â”€ requirements.txt      # Dipendenze
â”œâ”€â”€ pyproject.toml        # Configurazione progetto
â”œâ”€â”€ Makefile              # Automazione task
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Comandi Disponibili

```bash
make help          # Mostra tutti i comandi disponibili
make install       # Installa dipendenze
make setup         # Setup completo ambiente
make test          # Esegui test
make lint          # Controlla codice (flake8, mypy)
make format        # Formatta codice (black, isort)
make clean         # Pulisci file generati
make run-notebook  # Avvia Jupyter
make train         # Esegui training pipeline
```

---

## ğŸ§ª Testing

```bash
# Esegui tutti i test
make test

# Esegui test specifici
pytest tests/test_text_preprocessing.py -v

# Con coverage report
pytest --cov=src --cov-report=html
```

---

## ğŸ“Š Workflow Tipico

1. **Raccolta Dati**
   ```bash
   # Scraping web o caricamento file
   python scripts/scrape_data.py
   ```

2. **Preprocessing**
   - Apri `notebooks/nlp_pipeline.ipynb`
   - Esegui le celle di preprocessing
   - Salva dati puliti in `data/cleaned/`

3. **Training**
   ```bash
   python scripts/train_pipeline.py --input-file data/cleaned/data.csv
   ```

4. **Valutazione**
   - Metriche automatiche (accuracy, F1, precision, recall)
   - Confusion matrix
   - Classification report

5. **Deployment**
   - Modello salvato in `models/`
   - Pronto per produzione

---

## ğŸ”§ Configurazione

Copia `.env.example` in `.env` e modifica:

```bash
cp .env.example .env
```

```env
# Lingua default
DEFAULT_LANGUAGE=italian

# Preprocessing
USE_LEMMATIZATION=true
REMOVE_STOPWORDS=true

# Modellazione
TEST_SIZE=0.2
RANDOM_STATE=42
MAX_FEATURES=1000
```

---

## ğŸ“š Documentazione

- [Quick Start Guide](QUICKSTART.md) - Guida rapida con esempi
- [Best Practices](docs/BEST_PRACTICES.md) - Best practices NLP

---

## ğŸ¤ Contribuire

I contributi sono benvenuti! Per favore:

1. Fork il progetto
2. Crea un branch per la feature (`git checkout -b feature/AmazingFeature`)
3. Commit le modifiche (`git commit -m 'Add AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Apri una Pull Request

Vedi [CONTRIBUTING.md](CONTRIBUTING.md) per dettagli.

---

## ğŸ“ License

Distribuito sotto licenza MIT. Vedi `LICENSE` per maggiori informazioni.

---

## ğŸ‘¥ Autori

- **Your Name** - *Initial work*

---

## ğŸ™ Ringraziamenti

- NLTK Team
- spaCy Team
- scikit-learn Team
- Hugging Face

---

## ğŸ“ Contatti

- Email: your.email@example.com
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your Name](https://linkedin.com/in/yourprofile)

---

â­ **Se questo progetto ti Ã¨ stato utile, lascia una stella!**
